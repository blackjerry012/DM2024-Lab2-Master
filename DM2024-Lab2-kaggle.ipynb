{
 "cells": [
  {
   "attachments": {
    "ac045839-f11d-44e6-9414-7b17411f647c.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student infomation  \n",
    "Name:林澤宇  \n",
    "Student id:112064528  \n",
    "Github id:98965138  \n",
    "kaggle name:NTHU112064528  \n",
    "![image.png](attachment:ac045839-f11d-44e6-9414-7b17411f647c.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-03T17:37:42.62297Z",
     "iopub.status.busy": "2024-12-03T17:37:42.622175Z",
     "iopub.status.idle": "2024-12-03T17:38:12.859286Z",
     "shell.execute_reply": "2024-12-03T17:38:12.858546Z",
     "shell.execute_reply.started": "2024-12-03T17:37:42.622939Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics import Accuracy\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Download NLTK resources for text preprocessing\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Step 1: Load emotion and data identification datasets\n",
    "# Read the CSV file containing emotion labels\n",
    "emotion = pd.read_csv(\"/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv\")\n",
    "data_identification = pd.read_csv(\"/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv\")\n",
    "\n",
    "# Load and process tweets from the JSON file\n",
    "with open(\"/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json\", \"r\") as file:\n",
    "    tweets_raw = [json.loads(line) for line in file]\n",
    "\n",
    "tweets = pd.DataFrame([{\n",
    "    \"tweet_id\": tweet[\"_source\"][\"tweet\"][\"tweet_id\"],\n",
    "    \"text\": tweet[\"_source\"][\"tweet\"][\"text\"]\n",
    "} for tweet in tweets_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T17:38:12.861023Z",
     "iopub.status.busy": "2024-12-03T17:38:12.860763Z",
     "iopub.status.idle": "2024-12-03T17:38:19.942773Z",
     "shell.execute_reply": "2024-12-03T17:38:19.941719Z",
     "shell.execute_reply.started": "2024-12-03T17:38:12.860999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge `data_identification` with `tweets` on the common column \"tweet_id\"\n",
    "merged_data = pd.merge(data_identification, tweets, on=\"tweet_id\", how=\"left\")\n",
    "#Merge the result with `emotion` on \"tweet_id\"\n",
    "merged_data = pd.merge(merged_data, emotion, on=\"tweet_id\", how=\"left\")\n",
    "\n",
    "# 2.  Separate the merged dataset into training and testing sets\n",
    "train_data = merged_data[merged_data[\"identification\"] == \"train\"].copy()\n",
    "test_data = merged_data[merged_data[\"identification\"] == \"test\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T17:38:19.944201Z",
     "iopub.status.busy": "2024-12-03T17:38:19.943894Z",
     "iopub.status.idle": "2024-12-03T17:40:54.793109Z",
     "shell.execute_reply": "2024-12-03T17:40:54.792419Z",
     "shell.execute_reply.started": "2024-12-03T17:38:19.944174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Text preprocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "#Steps:\n",
    "#1. Convert emojis to descriptive words using `emoji.demojize`.\n",
    "#2. Remove URLs (e.g., \"http://example.com\").\n",
    "#3. Remove user mentions (e.g., \"@username\").\n",
    "#4. Retain hashtags but remove other punctuation and special characters.\n",
    "#5. Convert text to lowercase to ensure consistency.\n",
    "#6. Remove stopwords to focus on meaningful words.\n",
    "    \n",
    "def preprocess_text(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s#\\U0001F600-\\U0001F64F]\", \"\", text)\n",
    "    text = text.lower()\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    return \" \".join(words)  # required for BERT input\n",
    "\n",
    "train_data[\"cleaned_text\"] = train_data[\"text\"].apply(preprocess_text)\n",
    "test_data[\"cleaned_text\"] = test_data[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T17:40:54.795896Z",
     "iopub.status.busy": "2024-12-03T17:40:54.795536Z",
     "iopub.status.idle": "2024-12-03T17:40:54.988029Z",
     "shell.execute_reply": "2024-12-03T17:40:54.987367Z",
     "shell.execute_reply.started": "2024-12-03T17:40:54.795858Z"
    }
   },
   "outputs": [],
   "source": [
    "#Step 4: Label processing\n",
    "emotion_mapping = {emotion: idx for idx, emotion in enumerate(train_data[\"emotion\"].unique())}\n",
    "train_data[\"label\"] = train_data[\"emotion\"].map(emotion_mapping)\n",
    "test_data[\"label\"] = test_data[\"emotion\"].map(emotion_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T17:40:54.989197Z",
     "iopub.status.busy": "2024-12-03T17:40:54.988939Z",
     "iopub.status.idle": "2024-12-03T17:40:55.964731Z",
     "shell.execute_reply": "2024-12-03T17:40:55.963874Z",
     "shell.execute_reply.started": "2024-12-03T17:40:54.989172Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_data20% for val\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(train_data)}, Validation size: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T17:40:55.966018Z",
     "iopub.status.busy": "2024-12-03T17:40:55.965741Z",
     "iopub.status.idle": "2024-12-03T17:40:55.976713Z",
     "shell.execute_reply": "2024-12-03T17:40:55.975918Z",
     "shell.execute_reply.started": "2024-12-03T17:40:55.965993Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T17:40:55.978023Z",
     "iopub.status.busy": "2024-12-03T17:40:55.977781Z",
     "iopub.status.idle": "2024-12-03T17:40:55.988486Z",
     "shell.execute_reply": "2024-12-03T17:40:55.987791Z",
     "shell.execute_reply.started": "2024-12-03T17:40:55.977999Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Define datasets and load data\n",
    "class TwitterDataset(Dataset):\n",
    "    #-data (DataFrame): The input data containing 'cleaned_text' and 'label' columns.\n",
    "    #-tokenizer: The Hugging Face tokenizer for tokenizing text.\n",
    "    #-max_length (int): The maximum sequence length for padding and truncation.\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        text = row['cleaned_text'] # Preprocessed text\n",
    "        label = row['label']# Numeric label for the emotion\n",
    "        # Tokenize the text and prepare it for the model\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",# Pad to the maximum sequence length\n",
    "            truncation=True, # Truncate text longer than the maximum length\n",
    "            max_length=self.max_length,# Maximum sequence length\n",
    "            return_tensors=\"pt\"# Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),# Tokenized IDs\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),# Attention mask\n",
    "            'label': torch.tensor(label, dtype=torch.long) # Emotion label as a tensor\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    #- 'input_ids' (Tensor): Stacked input IDs for the batch.\n",
    "    #- 'attention_mask' (Tensor): Stacked attention masks for the batch.\n",
    "    #- 'labels' (Tensor): Stacked labels for the batch.\n",
    "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "    labels = torch.tensor([item['label'] for item in batch])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T17:40:55.990174Z",
     "iopub.status.busy": "2024-12-03T17:40:55.9896Z",
     "iopub.status.idle": "2024-12-03T17:40:56.002749Z",
     "shell.execute_reply": "2024-12-03T17:40:56.001949Z",
     "shell.execute_reply.started": "2024-12-03T17:40:55.990116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Initialize BERT model and classifier\n",
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\", num_classes=8):\n",
    "        #Initialize\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        # Extract the [CLS] token output (first token) from the last hidden state\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  \n",
    "        # Pass the [CLS] token output through the classifier to get logits\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T17:40:56.003993Z",
     "iopub.status.busy": "2024-12-03T17:40:56.003752Z",
     "iopub.status.idle": "2024-12-03T17:40:56.695045Z",
     "shell.execute_reply": "2024-12-03T17:40:56.694384Z",
     "shell.execute_reply.started": "2024-12-03T17:40:56.003969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7: Initialize model, optimizer, and loss function\n",
    "model = EmotionClassifier(num_classes=len(emotion_mapping)).to(device)\n",
    "# Load the pre-trained BERT tokenizer for text preprocessing\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 8: Construct data loaders\n",
    "max_length = 64\n",
    "batch_size = 8\n",
    "# Create DataLoader objects for batch processing\n",
    "train_dataset = TwitterDataset(train_data, tokenizer, max_length)\n",
    "#test_dataset = TwitterDataset(test_data, tokenizer, max_length)\n",
    "val_dataset = TwitterDataset(val_data, tokenizer, max_length)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "# - `train_dataloader` is ready to provide batches for training.\n",
    "# - `val_dataloader` is used for validating the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T17:40:56.698175Z",
     "iopub.status.busy": "2024-12-03T17:40:56.69789Z",
     "iopub.status.idle": "2024-12-03T17:40:56.705578Z",
     "shell.execute_reply": "2024-12-03T17:40:56.704778Z",
     "shell.execute_reply.started": "2024-12-03T17:40:56.69815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 9: Training and evaluation functions\n",
    "#Function to train the model for one epoch.\n",
    "def train(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # Zero out the gradients for the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass through the model\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        # Compute the loss between predictions and true labels\n",
    "        loss = loss_fn(logits, labels)\n",
    "        # Backward pass to compute gradients\n",
    "        loss.backward()\n",
    "        # Update model parameters using the optimizer\n",
    "        optimizer.step()\n",
    "        # Accumulate the loss for reporting\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "#Function to evaluate the model on a validation or test dataset.\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    # Initialize\n",
    "    accuracy_metric = Accuracy(task=\"multiclass\", num_classes=len(emotion_mapping)).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            # Forward pass through the model\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            # Compute the loss between predictions and true labels\n",
    "            loss = loss_fn(logits, labels)\n",
    "            # Accumulate the loss for reporting\n",
    "            total_loss += loss.item()\n",
    "            # Update the accuracy metric with the current batch predictions and labels\n",
    "            accuracy_metric.update(logits.argmax(dim=1), labels)\n",
    "    accuracy = accuracy_metric.compute().item()\n",
    "    accuracy_metric.reset()\n",
    "    # Return the average loss per batch and the overall accuracy\n",
    "    return total_loss / len(dataloader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T18:40:40.796698Z",
     "iopub.status.busy": "2024-12-03T18:40:40.796005Z",
     "iopub.status.idle": "2024-12-03T23:54:30.206405Z",
     "shell.execute_reply": "2024-12-03T23:54:30.205423Z",
     "shell.execute_reply.started": "2024-12-03T18:40:40.796662Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 1 #I only train for one epochs because of time. one epochs 5hr\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    \n",
    "    # train model\n",
    "    train_loss = train(model, train_dataloader, optimizer, loss_fn, device)\n",
    "    \n",
    "    # val model\n",
    "    val_loss, val_accuracy = evaluate(model, val_dataloader, loss_fn, device)\n",
    "    # Print the training loss for this epoch\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    # Print the validation loss and accuracy for this epoch\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T23:54:37.214477Z",
     "iopub.status.busy": "2024-12-03T23:54:37.214101Z",
     "iopub.status.idle": "2024-12-03T23:54:37.829677Z",
     "shell.execute_reply": "2024-12-03T23:54:37.828846Z",
     "shell.execute_reply.started": "2024-12-03T23:54:37.214445Z"
    }
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), \"bert_emotion_model.pth\")\n",
    "print(\"Model saved as bert_emotion_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T23:54:54.135389Z",
     "iopub.status.busy": "2024-12-03T23:54:54.135045Z",
     "iopub.status.idle": "2024-12-03T23:54:54.141525Z",
     "shell.execute_reply": "2024-12-03T23:54:54.140557Z",
     "shell.execute_reply.started": "2024-12-03T23:54:54.135358Z"
    }
   },
   "outputs": [],
   "source": [
    "#Same as class TwitterDataset but return tweet_id\n",
    "class TestTwitterDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        text = row['cleaned_text']\n",
    "        tweet_id = row['tweet_id']\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'id': tweet_id  # return tweet_id\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T23:55:06.576441Z",
     "iopub.status.busy": "2024-12-03T23:55:06.576082Z",
     "iopub.status.idle": "2024-12-03T23:55:06.58085Z",
     "shell.execute_reply": "2024-12-03T23:55:06.579767Z",
     "shell.execute_reply.started": "2024-12-03T23:55:06.576412Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = TestTwitterDataset(test_data, tokenizer, max_length)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T23:55:13.91439Z",
     "iopub.status.busy": "2024-12-03T23:55:13.914014Z",
     "iopub.status.idle": "2024-12-03T23:55:13.920076Z",
     "shell.execute_reply": "2024-12-03T23:55:13.919195Z",
     "shell.execute_reply.started": "2024-12-03T23:55:13.914359Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = [] # List to store predicted class labels\n",
    "    ids = []   # List to store tweet IDs from the test dataset\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            # Forward pass through the model to get prediction logits\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()  #Get predicted class labels\n",
    "            predictions.extend(preds)\n",
    "            ids.extend(batch['id'])  #Append tweet IDs to the list\n",
    "    \n",
    "    return ids, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T23:55:26.36001Z",
     "iopub.status.busy": "2024-12-03T23:55:26.359679Z",
     "iopub.status.idle": "2024-12-04T00:24:41.736327Z",
     "shell.execute_reply": "2024-12-04T00:24:41.735634Z",
     "shell.execute_reply.started": "2024-12-03T23:55:26.359983Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"bert_emotion_model.pth\")) # Load model weights from a file\n",
    "model.eval()   # Set the model to evaluation mode\n",
    "print(\"Model loaded and ready for testing.\")\n",
    "\n",
    "# Use the model to make predictions on the test dataset\n",
    "test_ids, test_predictions = predict(model, test_dataloader, device)\n",
    "\n",
    "# Convert predicted numeric labels into emotion names\n",
    "inverse_emotion_mapping = {v: k for k, v in emotion_mapping.items()}\n",
    "test_emotions = [inverse_emotion_mapping[pred] for pred in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T00:25:02.467087Z",
     "iopub.status.busy": "2024-12-04T00:25:02.46677Z",
     "iopub.status.idle": "2024-12-04T00:25:02.847046Z",
     "shell.execute_reply": "2024-12-04T00:25:02.846174Z",
     "shell.execute_reply.started": "2024-12-04T00:25:02.46706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"emotion\": test_emotions\n",
    "})\n",
    "\n",
    "# Save as CSV file\n",
    "submission.to_csv(\"sampleSubmission.csv\", index=False)\n",
    "print(\"Submission file saved as sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T00:25:09.567832Z",
     "iopub.status.busy": "2024-12-04T00:25:09.567524Z",
     "iopub.status.idle": "2024-12-04T00:25:09.57706Z",
     "shell.execute_reply": "2024-12-04T00:25:09.576092Z",
     "shell.execute_reply.started": "2024-12-04T00:25:09.567807Z"
    }
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T00:26:26.753652Z",
     "iopub.status.busy": "2024-12-04T00:26:26.75283Z",
     "iopub.status.idle": "2024-12-04T00:26:27.073459Z",
     "shell.execute_reply": "2024-12-04T00:26:27.072598Z",
     "shell.execute_reply.started": "2024-12-04T00:26:26.753618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save as CSV file\n",
    "submission.to_csv(\"/kaggle/working/sampleSubmission.csv\", index=False)\n",
    "print(\"Submission file saved at /kaggle/working/sampleSubmission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9912598,
     "sourceId": 87232,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
